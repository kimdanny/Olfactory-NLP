{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "controlling-bread",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn as sk\n",
    "import pandas as pd\n",
    "# Comment out if you did not ever face ssl error\n",
    "import ssl\n",
    "import numpy as np\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "strategic-manor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>categoryNumber</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It Wasn't Gas I Passed. The smell was in compa...</td>\n",
       "      <td>cat8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Foul Litter box. Whenever I walked into my...</td>\n",
       "      <td>cat8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I Can't Smell You. I, just tonight, had a cowo...</td>\n",
       "      <td>cat8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dragon Breath Teacher. Once a teacher yelled a...</td>\n",
       "      <td>cat8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The day I took a plunge. I was playing in a fi...</td>\n",
       "      <td>cat8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>New car smell. One particular smell experience...</td>\n",
       "      <td>cat4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>New Purse. I had been obsessing over a Marc Ja...</td>\n",
       "      <td>cat4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>Building a PC: A newcomer's experience. I was ...</td>\n",
       "      <td>cat4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>Scent of Skin. Smell of the skin, when growing...</td>\n",
       "      <td>cat4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>Coffee Reborn. The first time I walked into St...</td>\n",
       "      <td>cat4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>439 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text categoryNumber\n",
       "0    It Wasn't Gas I Passed. The smell was in compa...           cat8\n",
       "1    The Foul Litter box. Whenever I walked into my...           cat8\n",
       "2    I Can't Smell You. I, just tonight, had a cowo...           cat8\n",
       "3    Dragon Breath Teacher. Once a teacher yelled a...           cat8\n",
       "4    The day I took a plunge. I was playing in a fi...           cat8\n",
       "..                                                 ...            ...\n",
       "434  New car smell. One particular smell experience...           cat4\n",
       "435  New Purse. I had been obsessing over a Marc Ja...           cat4\n",
       "436  Building a PC: A newcomer's experience. I was ...           cat4\n",
       "437  Scent of Skin. Smell of the skin, when growing...           cat4\n",
       "438  Coffee Reborn. The first time I walked into St...           cat4\n",
       "\n",
       "[439 rows x 2 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./obrist-ground_truth.csv')\n",
    "df = df[['text', 'categoryNumber']]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "meaning-section",
   "metadata": {},
   "source": [
    "## textaug experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "velvet-approach",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textaugment import EDA, Translate, Wordnet, Word2vec\n",
    "from gensim.test.utils import datapath\n",
    "import gensim\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "accurate-knitting",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"It Wasn't Gas I Passed. The smell was in comparison to rotten eggs and the reason it is so memorable is because the source of the smell was coming from my mouth. I was in a small room full of people who assumed someone had released gas and was too embarrassed to fess up to the real source. Needless to say I called my mom to come and get me, and left as quickly as I could. I am sure they figured out the source once I was gone and it no longer smelled like that there.\""
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eda = EDA()\n",
    "df.loc[0, 'text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "legal-circular",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"It Wasn't Gas I Passed. The smell was in comparison to eggs and the reason it is so memorable is because the source of the smell was coming from mouth. was small room full of people who assumed someone released gas and was too embarrassed to fess up to the real source. to say I called my mom to come and get me, and left quickly as I could. I am sure they figured the source once was gone and it no longer smelled like that\""
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eda.random_deletion(df.loc[0, 'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "hearing-wealth",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"It Wasn't Gas I Passed. The smell was in comparison to rotten eggs and the reason it is so memorable is because the source of the smell was coming from my mouth. I was in a small room full of momma people who assumed someone had released gas and was too embarrassed to fess up to the real source. Needless to say I called my mom to come and get me, and left as quickly as I could. I am sure they figured out the source once I was gone and it no longer smelled like that there.\""
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eda.random_insertion(df.loc[0, 'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "considerable-aerospace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"It Wasn't Gas I Passed. The smell was in comparison to rotten eggs and the reason it is so memorable is because the source of the smell was coming from my mouth. I was in a small room full of people who assumed someone had released gas and was too embarrassed to fess up to the real source. Needless to say I called my the to come and get me, and left as quickly as I could. I am sure they figured out mom source once I was gone and it no longer smelled like that there.\""
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eda.random_swap(df.loc[0, 'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "afraid-insight",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_replace = int(len(df.loc[0, 'text']) * 0.1)\n",
    "n_replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "dental-sleep",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"information technology Wasn't blow i Passed. The smelling was in compare to rotted testicle and the understanding it is so memorable is because the reference of the smelling was total from my mouth. i was in a diminished way wide cut of the great unwashed who take for granted individual had expel blow and was too hinder to fez up to the very source. uncalled for to articulate i call off my mama to derive and scram me, and result as promptly as i could. i am for certain they fancy out the reference once i was done for and it no yearner reek ilk that there.\""
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eda.synonym_replacement(df.loc[0, 'text'], n=n_replace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cleared-collect",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'that was not the gas i passed through. the smell was comparable to rotten eggs because it was so memorable that the source of that smell came from my mouth. i was in a real room thinking that someone had released the gas and i was very embarrassed to know the real source. i called my mom to pick me up, needless to say i left as soon as i could. i hope they found the source as soon as i left, it no longer smells like that.'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = Translate(src=\"en\", to=\"ta\")\n",
    "t.augment(df.loc[0, 'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "sought-galaxy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-03-01 02:37:51--  https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\n",
      "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.217.194.112\n",
      "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.217.194.112|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1647046227 (1.5G) [application/x-gzip]\n",
      "Saving to: ‘GoogleNews-vectors-negative300.bin.gz’\n",
      "\n",
      "GoogleNews-vectors- 100%[===================>]   1.53G  13.4MB/s    in 2m 46s  \n",
      "\n",
      "2021-03-01 02:40:40 (9.46 MB/s) - ‘GoogleNews-vectors-negative300.bin.gz’ saved [1647046227/1647046227]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget \"https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "laughing-technique",
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "measured-prince",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_path = datapath(cwd + '/GoogleNews-vectors-negative300.bin.gz')\n",
    "\n",
    "# load model\n",
    "w2v_model = gensim.models.KeyedVectors.load_word2vec_format(pretrained_path, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "tutorial-peace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"it wasn't gas i passed. however smells was the comparison to disgusting hens and in reason what is so memorable is because the daybad of the pungent_smell was coming from me mouth. i became in a small room full of peo_ple why_shouldn'ta assumed someone been released gas and wasn'ta too disgusted to fess down to this kind source. unncessary to say i denounced my mom to come and gotten me, and leave asthe quickly although i could. i 5p.m sure they maybe onto the souce once i was come and it isno longer odor maybe actually there.\""
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv = Word2vec(model = w2v_model)\n",
    "wv_output = wv.augment(df.loc[0, 'text'])\n",
    "wv_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "adjustable-schedule",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'that was not the gas i passed through. however the smell is comparable to disgusting chicken and what is most memorable for the reason is that the daytime of pungent_smell comes from me. why did i do bio_bil in a small room, even if someone thought the gas was released, i never hated triggering this kind of source. needless to say i came and saw my mom, get out as soon as i can. i 5 p.m of course they might have come to the suis as soon as i arrived, it no longer smells.'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.augment(wv_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "rising-lincoln",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>categoryNumber</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1751</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1752</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1753</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1754</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1755</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1756 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     text categoryNumber\n",
       "0     NaN            NaN\n",
       "1     NaN            NaN\n",
       "2     NaN            NaN\n",
       "3     NaN            NaN\n",
       "4     NaN            NaN\n",
       "...   ...            ...\n",
       "1751  NaN            NaN\n",
       "1752  NaN            NaN\n",
       "1753  NaN            NaN\n",
       "1754  NaN            NaN\n",
       "1755  NaN            NaN\n",
       "\n",
       "[1756 rows x 2 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(index=[i for i in range(len(df)*4)], columns=['text', 'categoryNumber'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acquired-founder",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cloudy-start",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "reserved-newton",
   "metadata": {},
   "source": [
    "## Text Augmentation\n",
    "\n",
    "combination of methods include:\n",
    "\n",
    "\t- random deletion\n",
    "\t- random swap\n",
    "\t- random insertion\n",
    "\t- Wordnet based synonym replacement\n",
    "\t- Word2vec (GoogleNews-vectors) based synonym replacement\n",
    "\t- Back-translation ( eng-> X -> eng | X<- {ur (urdu), vi (vietnamese), ta (tamil)} )\n",
    "\n",
    "Chose urdu, vietnamese and tamil because they are linguistically far from english.\n",
    "If you use linguistically close language like spanish, german or french, you will get almost the same result with a little change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "separate-simpson",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from textaugment import EDA, Translate, Wordnet, Word2vec\n",
    "\n",
    "from random import randint, sample\n",
    "from urllib.error import HTTPError\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "insured-connection",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment(df, n_times=4, enable_w2v=False, w2v_model=None, verbose=True):\n",
    "    \"\"\"\n",
    "    <n_times>\n",
    "    If n_times==3:\n",
    "        1. Original Sentence\n",
    "        2. Random Noise injection\n",
    "        3. Synonym replacement\n",
    "    making your dataset three times bigger.\n",
    "    \n",
    "    If n_times==4:\n",
    "        additionally perform step 4\n",
    "        4. Back-translation\n",
    "    making your dataset four times bigger.\n",
    "    \n",
    "    \n",
    "    <Word2Vec based synonym replacement>\n",
    "    If you want to use word2vec based synonym substitution, \n",
    "    enable_w2v=True, w2v_model=<Your Model>\n",
    "    \n",
    "    <How to make your w2v model for this function parameter>\n",
    "        ```\n",
    "        # You can get another pre-trained embeddings, but for example,\n",
    "        !wget \"https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\"\n",
    "        \n",
    "        cwd = os.getcwd()\n",
    "        pretrained_path = datapath(cwd + '/GoogleNews-vectors-negative300.bin.gz')\n",
    "        w2v_model = gensim.models.KeyedVectors.load_word2vec_format(pretrained_path, binary=True)\n",
    "        ```\n",
    "    you should pass the w2v_model as one of parameters of this function.\n",
    "    \n",
    "    ### NOTICE ###\n",
    "    HOWEVER! Notice that if you use word2vec for substitution it will take loooong time...\n",
    "    \"\"\"\n",
    "    \n",
    "    # input verification\n",
    "    assert n_times==3 or n_times==4\n",
    "    result_df = pd.DataFrame(index=[i for i in range(len(df)*int(n_times))], columns=['text', 'categoryNumber'])\n",
    "    \n",
    "    if enable_w2v:\n",
    "        assert w2v_model is not None\n",
    "        wv = Word2vec(model = w2v_model)\n",
    "    \n",
    "    eda = EDA()\n",
    "    \n",
    "    for i, row in df.iterrows():\n",
    "        sentence_original = row.text\n",
    "        cat = row.categoryNumber\n",
    "        \n",
    "        # 1. put original text into result_df\n",
    "        result_df.at[n_times*i, 'text'] = sentence_original\n",
    "        result_df.at[n_times*i, 'categoryNumber'] = cat\n",
    "        \n",
    "        # Add random noise by two of (deletion:1, swap:2, insertion:3)\n",
    "        sentence_noised = sentence_original\n",
    "        for rand in sample(range(1, 4), 2):  # sampled two random numbers from 1 to 3\n",
    "            if rand==1:    # deletion\n",
    "                sentence_noised = eda.random_deletion(sentence_noised)\n",
    "            elif rand==2:  # swap\n",
    "                sentence_noised = eda.random_swap(sentence_noised)\n",
    "            else:          # insertion\n",
    "                sentence_noised = eda.random_insertion(sentence_noised)\n",
    "        \n",
    "        # 2. put noised sentence into the second entry in result_df\n",
    "        result_df.at[n_times*i + 1, 'text'] = sentence_noised\n",
    "        result_df.at[n_times*i + 1, 'categoryNumber'] = cat\n",
    "        \n",
    "        if verbose and i%50==0:\n",
    "            print(f\"Iteration{i}: Sentence Noising Finished\")\n",
    "        \n",
    "        \n",
    "        # Synonym replacement\n",
    "        n_replace = int(len(sentence_noised) * 0.1)\n",
    "        \n",
    "        if enable_w2v:  # make randomness between choice of wordnet and word2vec\n",
    "            rand_num = randint(0, 1)\n",
    "            if rand_num==0:  # wordnet\n",
    "                sentence_replaced = eda.synonym_replacement(sentence_noised, n=n_replace)\n",
    "            else:            # word2vec\n",
    "                sentence_replaced = wv.augment(sentence_noised)\n",
    "                \n",
    "        else:   # No randomness: wordnet based replacement for all\n",
    "            sentence_replaced = eda.synonym_replacement(sentence_noised, n=n_replace)\n",
    "        \n",
    "        # 3. put replaced sentence into the third entry in result_df\n",
    "        result_df.at[n_times*i + 2, 'text'] = sentence_replaced\n",
    "        result_df.at[n_times*i + 2, 'categoryNumber'] = cat\n",
    "        \n",
    "        if verbose and i%50==0:\n",
    "            print(f\"Iteration{i}: Synonym Replacement Finished\")\n",
    "        \n",
    "        if n_times==4:\n",
    "            # Back-translation\n",
    "            rand_num = randint(1, 3)  # ur:1, vi:2, ta:3\n",
    "            if rand_num==1:     # ur\n",
    "                trans = Translate(src=\"en\", to=\"ur\")\n",
    "            elif rand_num==2:   # vi\n",
    "                trans = Translate(src=\"en\", to=\"vi\")\n",
    "            else:               # ta\n",
    "                trans = Translate(src=\"en\", to=\"ta\")\n",
    "                \n",
    "            try:\n",
    "                sentence_trans = t.augment(sentence_replaced)\n",
    "            except HTTPError:\n",
    "                print(\"Got HTTP Error 429: Too Many Requests, so sleeping for 10 seconds\")\n",
    "                time.sleep(10)\n",
    "                sentence_trans = t.augment(sentence_replaced)\n",
    "            \n",
    "            # 4. put back-translated sentence into the fourth entry in result_df\n",
    "            result_df.at[n_times*i + 3, 'text'] = sentence_trans\n",
    "            result_df.at[n_times*i + 3, 'categoryNumber'] = cat\n",
    "            \n",
    "            if verbose and i%50==0:\n",
    "                print(f\"Iteration{i}: Back-translation Finished\")\n",
    "            \n",
    "    return result_df        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "powered-graphic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration0: Sentence Noising Finished\n",
      "Iteration0: Synonym Replacement Finished\n",
      "Iteration50: Sentence Noising Finished\n",
      "Iteration50: Synonym Replacement Finished\n",
      "Iteration100: Sentence Noising Finished\n",
      "Iteration100: Synonym Replacement Finished\n",
      "Iteration150: Sentence Noising Finished\n",
      "Iteration150: Synonym Replacement Finished\n",
      "Iteration200: Sentence Noising Finished\n",
      "Iteration200: Synonym Replacement Finished\n",
      "Iteration250: Sentence Noising Finished\n",
      "Iteration250: Synonym Replacement Finished\n",
      "Iteration300: Sentence Noising Finished\n",
      "Iteration300: Synonym Replacement Finished\n",
      "Iteration350: Sentence Noising Finished\n",
      "Iteration350: Synonym Replacement Finished\n",
      "Iteration400: Sentence Noising Finished\n",
      "Iteration400: Synonym Replacement Finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>categoryNumber</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It Wasn't Gas I Passed. The smell was in compa...</td>\n",
       "      <td>cat8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It Wasn't Gas I Passed. was in comparison rott...</td>\n",
       "      <td>cat8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>information technology Wasn't gas ace Passed. ...</td>\n",
       "      <td>cat8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Foul Litter box. Whenever I walked into my...</td>\n",
       "      <td>cat8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Foul Litter box. Whenever I murder walked into...</td>\n",
       "      <td>cat8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1312</th>\n",
       "      <td>Scent of Skin. Smell of the skin, when growing...</td>\n",
       "      <td>cat4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1313</th>\n",
       "      <td>fragrance of Skin. flavor of the skin, when de...</td>\n",
       "      <td>cat4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1314</th>\n",
       "      <td>Coffee Reborn. The first time I walked into St...</td>\n",
       "      <td>cat4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1315</th>\n",
       "      <td>Coffee first I walked into SteamDot, the fines...</td>\n",
       "      <td>cat4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1316</th>\n",
       "      <td>coffee number  i take the air into SteamDot, t...</td>\n",
       "      <td>cat4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1317 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text categoryNumber\n",
       "0     It Wasn't Gas I Passed. The smell was in compa...           cat8\n",
       "1     It Wasn't Gas I Passed. was in comparison rott...           cat8\n",
       "2     information technology Wasn't gas ace Passed. ...           cat8\n",
       "3     The Foul Litter box. Whenever I walked into my...           cat8\n",
       "4     Foul Litter box. Whenever I murder walked into...           cat8\n",
       "...                                                 ...            ...\n",
       "1312  Scent of Skin. Smell of the skin, when growing...           cat4\n",
       "1313  fragrance of Skin. flavor of the skin, when de...           cat4\n",
       "1314  Coffee Reborn. The first time I walked into St...           cat4\n",
       "1315  Coffee first I walked into SteamDot, the fines...           cat4\n",
       "1316  coffee number  i take the air into SteamDot, t...           cat4\n",
       "\n",
       "[1317 rows x 2 columns]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "augmented_df3 = augment(df, n_times=3)\n",
    "augmented_df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "rolled-lightweight",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_df3.to_csv('./augmented_no_backtrans.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "first-basin",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "varied-color",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Need to handle HTTP Error 429: Too Many Requests\n",
    "# Sleeping for seconds doesnt help.\n",
    "# Probably have to use Google API for this or implement my own NMT model... overkill.. there must be a way\n",
    "augmented_df4 = augment(df, n_times=4)\n",
    "augmented_df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "devoted-merchandise",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_df4.to_csv('./augmented_with_backtrans.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
